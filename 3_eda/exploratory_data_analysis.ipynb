{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis - Jupyter Notebook\n",
    "================================================"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook contains the results of the Exploratory Data Analysis (EDA).\n",
    "\n",
    "Ideas are taken from the book:  \n",
    "Mukhiya, S. K., & Ahmed, U. (2020). Hands-On Exploratory Data Analysis with Python: Perform EDA Techniques to Understand, Summarize, and Investigate Your Data. Packt Publishing.\n",
    "\n",
    "\n",
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Load Data ### Filepath:  ../2_data/sickness_table.csv\n",
      "### Load Data ### Structure (first 5 rows): \n",
      "    Unnamed: 0        date  n_sick   calls  n_duty  n_sby  sby_need  dafted\n",
      "0           0  2016-04-01      73  8154.0    1700     90       4.0     0.0\n",
      "1           1  2016-04-02      64  8526.0    1700     90      70.0     0.0\n",
      "2           2  2016-04-03      68  8088.0    1700     90       0.0     0.0\n",
      "3           3  2016-04-04      71  7044.0    1700     90       0.0     0.0\n",
      "4           4  2016-04-05      63  7236.0    1700     90       0.0     0.0\n"
     ]
    }
   ],
   "source": [
    "# Operating system functionalities to join pathname components\n",
    "import os\n",
    "# Pandas for DataFrame and CSV handling\n",
    "import pandas as pd\n",
    "\n",
    "# Join the filepath of the raw data file\n",
    "filepath = os.path.join(\"..\", \"2_data\",\"sickness_table.csv\")\n",
    "print(\"### Load Data ### Filepath: \", filepath)\n",
    "\n",
    "# Read the data from CSV file\n",
    "data_raw = pd.read_csv(filepath)\n",
    "print(\"### Load Data ### Structure (first 5 rows): \\n\", data_raw.head(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is therefore structured tiem series data, with the following columns:\n",
    "- (unnamed): Row number\n",
    "- date: Date\n",
    "- n_sick: Number of emergency drivers who have registered a sick call\n",
    "- calls: Number of emergency calls\n",
    "- n_duty: Number of emergency drivers on duty\n",
    "- n_sby: Number of available substitute drivers\n",
    "- sby_need: Number of substitute drivers to be activated\n",
    "- dafted: Number of additional duty drivers that have to be activated if the number of on-call drivers are not sufficient"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structure Overview\n",
    "\n",
    "At first, get an overview about the data structure.\n",
    "\n",
    "### Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Data Overview ### Data types: \n",
      " Unnamed: 0      int64\n",
      "date           object\n",
      "n_sick          int64\n",
      "calls         float64\n",
      "n_duty          int64\n",
      "n_sby           int64\n",
      "sby_need      float64\n",
      "dafted        float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Get the data types of the columns\n",
    "print(\"### Data Overview ### Data types: \\n\",data_raw.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns contain either integer or float values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Conversions\n",
    "### Date\n",
    "\n",
    "The date field is an object, so we need to convert it into a DateTime argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Data Conversion ### First 5 rows after convert date: \n",
      "    Unnamed: 0                      date  n_sick   calls  n_duty  n_sby  \\\n",
      "0           0 2016-04-01 00:00:00+00:00      73  8154.0    1700     90   \n",
      "1           1 2016-04-02 00:00:00+00:00      64  8526.0    1700     90   \n",
      "2           2 2016-04-03 00:00:00+00:00      68  8088.0    1700     90   \n",
      "3           3 2016-04-04 00:00:00+00:00      71  7044.0    1700     90   \n",
      "4           4 2016-04-05 00:00:00+00:00      63  7236.0    1700     90   \n",
      "\n",
      "   sby_need  dafted  \n",
      "0       4.0     0.0  \n",
      "1      70.0     0.0  \n",
      "2       0.0     0.0  \n",
      "3       0.0     0.0  \n",
      "4       0.0     0.0  \n",
      "### Data Conversion ### Data types after convert date: \n",
      " Unnamed: 0                  int64\n",
      "date          datetime64[ns, UTC]\n",
      "n_sick                      int64\n",
      "calls                     float64\n",
      "n_duty                      int64\n",
      "n_sby                       int64\n",
      "sby_need                  float64\n",
      "dafted                    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Copy the data for conversion into a new variable\n",
    "data = data_raw\n",
    "# Convert the date objects into DateTime\n",
    "data.date = data.date.apply(lambda x: pd.to_datetime(x,\n",
    "errors='coerce', utc=True))\n",
    "print(\"### Data Conversion ### First 5 rows after convert date: \\n\", data.head(5))\n",
    "# Get the data types of the columns again\n",
    "print(\"### Data Conversion ### Data types after convert date: \\n\",data.dtypes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "### Detect missing values\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    False\n",
       "date          False\n",
       "n_sick        False\n",
       "calls         False\n",
       "n_duty        False\n",
       "n_sby         False\n",
       "sby_need      False\n",
       "dafted        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detect missing values (invert the boolean value which indicates not non-missing values within the columns)\n",
    "~data.notna().any()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values within the dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "TODO: Gain inside from the data we have\n",
    "\n",
    "### Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.mean()\n",
    "#data.median()\n",
    "#import matplotlib as plt\n",
    "#plt.plot(data.date, data.n_sick)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dutySchedule_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6913ccc9ce5f215f64980cc9576bfffc64b3ea55643bf3a7938d14e6344a8d8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
